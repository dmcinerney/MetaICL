{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c895fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import json\n",
    "import string\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import GPT2Tokenizer, AutoTokenizer\n",
    "\n",
    "from metaicl.data import MetaICLData\n",
    "from metaicl.model import MetaICLModel\n",
    "\n",
    "from utils.data import load_data\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "        \n",
    "def get_performance(task, task_train_data, task_dev_data, k, trim_dev_data, checkpoint, prompt_seed, add_newlines=True):\n",
    "    random.seed(prompt_seed)\n",
    "    #                 curr_dev_data = random.sample(task_train_data, args.trim_dev_data)\n",
    "    curr_dev_data = task_dev_data[:trim_dev_data]\n",
    "    curr_train_data = random.sample(task_train_data, k)\n",
    "    assert len(curr_dev_data)>0\n",
    "    assert not args.use_demonstrations or len(curr_train_data)==k, \\\n",
    "            (args.use_demonstrations, len(curr_train_data), k)\n",
    "\n",
    "    config_file = \"config/tasks/{}.json\".format(task)\n",
    "    assert os.path.exists(config_file), config_file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    is_classification = config[\"task_type\"]==\"classification\"\n",
    "    if is_classification:\n",
    "        options = curr_dev_data[0][\"options\"]\n",
    "        assert np.all([d[\"options\"]==options for d in curr_dev_data])\n",
    "\n",
    "    result = run(logger, task, metaicl_data, metaicl_model,\n",
    "                 curr_train_data, curr_dev_data, seed, checkpoint, is_classification, add_newlines, args)\n",
    "\n",
    "    if result is None:\n",
    "        errors.append(\"%s/%s\" % (task, seed))\n",
    "    else:\n",
    "        return {\n",
    "            'k': args.k,\n",
    "            'task': task,\n",
    "            'prompt_seed': prompt_seed,\n",
    "            'train_samples': curr_train_data,\n",
    "            'result': result,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_out_name(out_dir, task, split_name, method, add_newlines, seed, args):\n",
    "    return os.path.join(\n",
    "        out_dir, \"{}-{}-{}{}{}{}{}\".format(\n",
    "            task,\n",
    "            split_name,\n",
    "            method,\n",
    "            \"-k={}\".format(args.k) if args.use_demonstrations else \"\",\n",
    "            \"-s={}\".format(seed) if args.use_demonstrations or args.use_random_english_words else \"\",\n",
    "            \"\" if add_newlines else \"-no-newlines\",\n",
    "            \"-randomEnglish\" if args.use_random_english_words else \"\"))\n",
    "\n",
    "\n",
    "def run(logger, task, metaicl_data, metaicl_model, train_data, dev_data, seed,\n",
    "        checkpoint, is_classification, add_newlines, args):\n",
    "#     import pdb; pdb.set_trace()\n",
    "\n",
    "    if args.do_zeroshot:\n",
    "        split_name = args.split\n",
    "        if args.is_null:\n",
    "            split_name += \"-null\"\n",
    "        cache_path = get_out_name(args.out_dir, task, split_name, metaicl_data.method, add_newlines, seed, args)+ \".pkl\"\n",
    "    else:\n",
    "        assert add_newlines\n",
    "        cache_path = get_out_name(args.out_dir, task, args.split, metaicl_data.method, False, seed, args)+ \".pkl\"\n",
    "\n",
    "    metaicl_data.tensorize(train_data, dev_data, add_newlines=add_newlines)\n",
    "    metaicl_data.print_tensorized_example()\n",
    "    logger.info(cache_path)\n",
    "    prediction_path = cache_path.replace(\".pkl\", \".txt\")\n",
    "    if args.use_calibration:\n",
    "        prediction_path = prediction_path.replace(\".txt\", \"-calibrated.txt\")\n",
    "\n",
    "#     if os.path.exists(prediction_path):\n",
    "#         return 0\n",
    "\n",
    "#     if os.path.exists(cache_path):\n",
    "#         with open(cache_path, \"rb\") as f:\n",
    "#             losses = pkl.load(f)\n",
    "    if False:\n",
    "        pass\n",
    "    else:\n",
    "        if metaicl_model.is_none():\n",
    "            metaicl_model.load(checkpoint, gpt2=args.gpt2)\n",
    "            metaicl_model.cuda()\n",
    "            metaicl_model.eval()\n",
    "\n",
    "        losses = metaicl_model.do_inference(metaicl_data, args.test_batch_size)\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pkl.dump(losses, f)\n",
    "\n",
    "    assert len(losses)==len(metaicl_data)\n",
    "\n",
    "    if args.is_null:\n",
    "        return None\n",
    "\n",
    "    if args.use_calibration:\n",
    "        assert args.do_zeroshot\n",
    "        bias_path = cache_path.replace(\"/\"+task+\"-\"+args.split, \"/\"+task+\"-\"+args.split+\"-null\")\n",
    "        assert os.path.exists(bias_path), bias_path\n",
    "        with open(bias_path, \"rb\") as f:\n",
    "            bias_losses = pkl.load(f)\n",
    "\n",
    "        losses = np.array(losses)\n",
    "        bias_losses = np.array(bias_losses)\n",
    "        assert losses.shape == bias_losses.shape\n",
    "        losses -= bias_losses\n",
    "\n",
    "    predictions = metaicl_model.do_predict(metaicl_data, losses=losses)\n",
    "    groundtruths = [dp[\"output\"] for dp in dev_data]\n",
    "    perf = metaicl_data.evaluate(predictions, groundtruths, is_classification)\n",
    "    logger.info(\"Accuracy=%s\" % perf)\n",
    "\n",
    "    with open(prediction_path, \"w\") as f:\n",
    "        for prediction in predictions:\n",
    "            f.write(prediction)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    return perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b024c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "args.gpt2 = 'gpt2-large'\n",
    "args.do_zeroshot = False\n",
    "args.checkpoint = 'gpt2-large'\n",
    "args.global_step = None\n",
    "args.use_demonstrations = True\n",
    "args.do_zeroshot = False\n",
    "args.k = 16\n",
    "args.out_dir = None\n",
    "args.test_batch_size = 16\n",
    "args.method = 'direct'\n",
    "args.task = 'custom'\n",
    "args.unseen_domain_only = False\n",
    "args.dataset = 'ethos-national_origin'\n",
    "args.split = 'dev'\n",
    "args.is_null = False\n",
    "args.out_dir = 'results/results_gpt2'\n",
    "args.seed = '100'\n",
    "args.use_random_english_words = False\n",
    "args.use_calibration = False\n",
    "args.num_prompt_samples = 32\n",
    "args.ks = [4]\n",
    "args.trim_dev_data = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0960ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 09:45:47 - INFO - __main__ - <__main__.Namespace object at 0x2b57d5fe5f70>\n"
     ]
    }
   ],
   "source": [
    "config_split = \"unseen_domain_test\" if args.unseen_domain_only else \"test\"\n",
    "handlers = [logging.StreamHandler()]\n",
    "# if args.log_file is not None:\n",
    "#     handlers.append(logging.FileHandler(args.log_file))\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=handlers)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57fb05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 09:45:48 - INFO - __main__ - Setting up for local_rank=-1, world_size=1\n",
      "07/06/2022 09:45:48 - INFO - __main__ - batch_size=16\tmax_length=1024\tmax_length_per_example=256\n"
     ]
    }
   ],
   "source": [
    "if args.gpt2.startswith(\"gpt2\"):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(args.gpt2)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "add_newlines = True\n",
    "\n",
    "### checkpoint ...\n",
    "if not args.do_zeroshot:\n",
    "    if args.checkpoint is not None:\n",
    "        checkpoint = args.checkpoint\n",
    "        assert args.global_step is None\n",
    "    else:\n",
    "        assert args.global_step is not None\n",
    "        checkpoint = os.path.join(args.out_dir, \"model-{}.pt\".format(args.global_step))\n",
    "#     assert os.path.exists(checkpoint)\n",
    "else:\n",
    "    add_newlines = not args.gpt2.startswith(\"gpt2\")\n",
    "    if False: #args.gpt2==\"gpt-j-6B\":\n",
    "        # we are using the HF veresion where GPT-J-6B checkpoint is not officially registered\n",
    "        # so need to download the model checkpoint and specify checkpoint\n",
    "        assert args.checkpoint is not None and os.path.exists(args.checkpoint)\n",
    "        args.gpt2 = args.checkpoint\n",
    "    checkpoint = None\n",
    "metaicl_model = MetaICLModel(logger, args.out_dir)\n",
    "\n",
    "if not os.path.exists(args.out_dir):\n",
    "    os.makedirs(args.out_dir)\n",
    "\n",
    "# setup hyperparams for data\n",
    "\n",
    "max_length_per_example = 256\n",
    "max_length = 256\n",
    "if args.use_demonstrations:\n",
    "    orig_max_length = max_length\n",
    "    if args.do_zeroshot:\n",
    "        max_length = min(max_length * args.k, 1024)\n",
    "    else:\n",
    "        max_length = min(max_length * args.k, 1024)\n",
    "\n",
    "logger.info(\"batch_size=%d\\tmax_length=%d\\tmax_length_per_example=%d\" % (\n",
    "    args.test_batch_size, max_length, max_length_per_example))\n",
    "\n",
    "metaicl_data = MetaICLData(logger, tokenizer, args.method, args.use_demonstrations, args.k,\n",
    "                           max_length, max_length_per_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288a6ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>task</th>\n",
       "      <th>prompt_seed</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>result</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>gpt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>quarel</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>quarel</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'task': 'quarel', 'input': 'Lisa and Melissa...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>quarel</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'task': 'quarel', 'input': 'Pete is running ...</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>quarel</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'task': 'quarel', 'input': \"A kitten crawled...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>quarel</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'task': 'quarel', 'input': 'A glass box is l...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>32</td>\n",
       "      <td>tweet_eval-stance_feminist</td>\n",
       "      <td>27</td>\n",
       "      <td>[{'task': 'tweet_eval-stance_feminist', 'input...</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>32</td>\n",
       "      <td>tweet_eval-stance_feminist</td>\n",
       "      <td>28</td>\n",
       "      <td>[{'task': 'tweet_eval-stance_feminist', 'input...</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>32</td>\n",
       "      <td>tweet_eval-stance_feminist</td>\n",
       "      <td>29</td>\n",
       "      <td>[{'task': 'tweet_eval-stance_feminist', 'input...</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>32</td>\n",
       "      <td>tweet_eval-stance_feminist</td>\n",
       "      <td>30</td>\n",
       "      <td>[{'task': 'tweet_eval-stance_feminist', 'input...</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>32</td>\n",
       "      <td>tweet_eval-stance_feminist</td>\n",
       "      <td>31</td>\n",
       "      <td>[{'task': 'tweet_eval-stance_feminist', 'input...</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4825 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       k                        task  prompt_seed  \\\n",
       "0      0                      quarel            0   \n",
       "1      1                      quarel            0   \n",
       "2      1                      quarel            1   \n",
       "3      1                      quarel            2   \n",
       "4      1                      quarel            3   \n",
       "...   ..                         ...          ...   \n",
       "4820  32  tweet_eval-stance_feminist           27   \n",
       "4821  32  tweet_eval-stance_feminist           28   \n",
       "4822  32  tweet_eval-stance_feminist           29   \n",
       "4823  32  tweet_eval-stance_feminist           30   \n",
       "4824  32  tweet_eval-stance_feminist           31   \n",
       "\n",
       "                                          train_samples    result  checkpoint  \\\n",
       "0                                                    []  0.687500  gpt2-large   \n",
       "1     [{'task': 'quarel', 'input': 'Lisa and Melissa...  0.687500  gpt2-large   \n",
       "2     [{'task': 'quarel', 'input': 'Pete is running ...  0.656250  gpt2-large   \n",
       "3     [{'task': 'quarel', 'input': \"A kitten crawled...  0.625000  gpt2-large   \n",
       "4     [{'task': 'quarel', 'input': 'A glass box is l...  0.687500  gpt2-large   \n",
       "...                                                 ...       ...         ...   \n",
       "4820  [{'task': 'tweet_eval-stance_feminist', 'input...  0.170543  gpt2-large   \n",
       "4821  [{'task': 'tweet_eval-stance_feminist', 'input...  0.170543  gpt2-large   \n",
       "4822  [{'task': 'tweet_eval-stance_feminist', 'input...  0.170543  gpt2-large   \n",
       "4823  [{'task': 'tweet_eval-stance_feminist', 'input...  0.170543  gpt2-large   \n",
       "4824  [{'task': 'tweet_eval-stance_feminist', 'input...  0.170543  gpt2-large   \n",
       "\n",
       "            gpt2  \n",
       "0     gpt2-large  \n",
       "1     gpt2-large  \n",
       "2     gpt2-large  \n",
       "3     gpt2-large  \n",
       "4     gpt2-large  \n",
       "...          ...  \n",
       "4820  gpt2-large  \n",
       "4821  gpt2-large  \n",
       "4822  gpt2-large  \n",
       "4823  gpt2-large  \n",
       "4824  gpt2-large  \n",
       "\n",
       "[4825 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(args.out_dir, 'results.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44477b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>task</th>\n",
       "      <th>prompt_seed</th>\n",
       "      <th>train_samples</th>\n",
       "      <th>result</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>gpt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'D...</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'o...</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'a...</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>3</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'a...</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'a...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'F...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>6</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': \"S...</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>7</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'b...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'F...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>9</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'T...</td>\n",
       "      <td>0.405670</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': \"S...</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>11</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'N...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>12</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'W...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>13</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'S...</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>14</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'U...</td>\n",
       "      <td>0.464039</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>15</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'A...</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'T...</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>17</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'G...</td>\n",
       "      <td>0.263263</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>18</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': \"I...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>19</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'F...</td>\n",
       "      <td>0.263263</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>20</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'I...</td>\n",
       "      <td>0.455455</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>21</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'T...</td>\n",
       "      <td>0.464039</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>22</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'B...</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>23</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'U...</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>24</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'S...</td>\n",
       "      <td>0.301587</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>25</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 't...</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>26</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'f...</td>\n",
       "      <td>0.468231</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>27</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'K...</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>28</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'Y...</td>\n",
       "      <td>0.343109</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>29</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'B...</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>30</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'I...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>4</td>\n",
       "      <td>ethos-national_origin</td>\n",
       "      <td>31</td>\n",
       "      <td>[{'task': 'ethos-national_origin', 'input': 'I...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>gpt2-large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k                   task  prompt_seed  \\\n",
       "2767  4  ethos-national_origin            0   \n",
       "2768  4  ethos-national_origin            1   \n",
       "2769  4  ethos-national_origin            2   \n",
       "2770  4  ethos-national_origin            3   \n",
       "2771  4  ethos-national_origin            4   \n",
       "2772  4  ethos-national_origin            5   \n",
       "2773  4  ethos-national_origin            6   \n",
       "2774  4  ethos-national_origin            7   \n",
       "2775  4  ethos-national_origin            8   \n",
       "2776  4  ethos-national_origin            9   \n",
       "2777  4  ethos-national_origin           10   \n",
       "2778  4  ethos-national_origin           11   \n",
       "2779  4  ethos-national_origin           12   \n",
       "2780  4  ethos-national_origin           13   \n",
       "2781  4  ethos-national_origin           14   \n",
       "2782  4  ethos-national_origin           15   \n",
       "2783  4  ethos-national_origin           16   \n",
       "2784  4  ethos-national_origin           17   \n",
       "2785  4  ethos-national_origin           18   \n",
       "2786  4  ethos-national_origin           19   \n",
       "2787  4  ethos-national_origin           20   \n",
       "2788  4  ethos-national_origin           21   \n",
       "2789  4  ethos-national_origin           22   \n",
       "2790  4  ethos-national_origin           23   \n",
       "2791  4  ethos-national_origin           24   \n",
       "2792  4  ethos-national_origin           25   \n",
       "2793  4  ethos-national_origin           26   \n",
       "2794  4  ethos-national_origin           27   \n",
       "2795  4  ethos-national_origin           28   \n",
       "2796  4  ethos-national_origin           29   \n",
       "2797  4  ethos-national_origin           30   \n",
       "2798  4  ethos-national_origin           31   \n",
       "\n",
       "                                          train_samples    result  checkpoint  \\\n",
       "2767  [{'task': 'ethos-national_origin', 'input': 'D...  0.365079  gpt2-large   \n",
       "2768  [{'task': 'ethos-national_origin', 'input': 'o...  0.301587  gpt2-large   \n",
       "2769  [{'task': 'ethos-national_origin', 'input': 'a...  0.337931  gpt2-large   \n",
       "2770  [{'task': 'ethos-national_origin', 'input': 'a...  0.301587  gpt2-large   \n",
       "2771  [{'task': 'ethos-national_origin', 'input': 'a...  0.179487  gpt2-large   \n",
       "2772  [{'task': 'ethos-national_origin', 'input': 'F...  0.179487  gpt2-large   \n",
       "2773  [{'task': 'ethos-national_origin', 'input': \"S...  0.337931  gpt2-large   \n",
       "2774  [{'task': 'ethos-national_origin', 'input': 'b...  0.179487  gpt2-large   \n",
       "2775  [{'task': 'ethos-national_origin', 'input': 'F...  0.179487  gpt2-large   \n",
       "2776  [{'task': 'ethos-national_origin', 'input': 'T...  0.405670  gpt2-large   \n",
       "2777  [{'task': 'ethos-national_origin', 'input': \"S...  0.372549  gpt2-large   \n",
       "2778  [{'task': 'ethos-national_origin', 'input': 'N...  0.179487  gpt2-large   \n",
       "2779  [{'task': 'ethos-national_origin', 'input': 'W...  0.437500  gpt2-large   \n",
       "2780  [{'task': 'ethos-national_origin', 'input': 'S...  0.301587  gpt2-large   \n",
       "2781  [{'task': 'ethos-national_origin', 'input': 'U...  0.464039  gpt2-large   \n",
       "2782  [{'task': 'ethos-national_origin', 'input': 'A...  0.222672  gpt2-large   \n",
       "2783  [{'task': 'ethos-national_origin', 'input': 'T...  0.337931  gpt2-large   \n",
       "2784  [{'task': 'ethos-national_origin', 'input': 'G...  0.263263  gpt2-large   \n",
       "2785  [{'task': 'ethos-national_origin', 'input': \"I...  0.437500  gpt2-large   \n",
       "2786  [{'task': 'ethos-national_origin', 'input': 'F...  0.263263  gpt2-large   \n",
       "2787  [{'task': 'ethos-national_origin', 'input': 'I...  0.455455  gpt2-large   \n",
       "2788  [{'task': 'ethos-national_origin', 'input': 'T...  0.464039  gpt2-large   \n",
       "2789  [{'task': 'ethos-national_origin', 'input': 'B...  0.238095  gpt2-large   \n",
       "2790  [{'task': 'ethos-national_origin', 'input': 'U...  0.222672  gpt2-large   \n",
       "2791  [{'task': 'ethos-national_origin', 'input': 'S...  0.301587  gpt2-large   \n",
       "2792  [{'task': 'ethos-national_origin', 'input': 't...  0.365079  gpt2-large   \n",
       "2793  [{'task': 'ethos-national_origin', 'input': 'f...  0.468231  gpt2-large   \n",
       "2794  [{'task': 'ethos-national_origin', 'input': 'K...  0.222672  gpt2-large   \n",
       "2795  [{'task': 'ethos-national_origin', 'input': 'Y...  0.343109  gpt2-large   \n",
       "2796  [{'task': 'ethos-national_origin', 'input': 'B...  0.337931  gpt2-large   \n",
       "2797  [{'task': 'ethos-national_origin', 'input': 'I...  0.437500  gpt2-large   \n",
       "2798  [{'task': 'ethos-national_origin', 'input': 'I...  0.179487  gpt2-large   \n",
       "\n",
       "            gpt2  \n",
       "2767  gpt2-large  \n",
       "2768  gpt2-large  \n",
       "2769  gpt2-large  \n",
       "2770  gpt2-large  \n",
       "2771  gpt2-large  \n",
       "2772  gpt2-large  \n",
       "2773  gpt2-large  \n",
       "2774  gpt2-large  \n",
       "2775  gpt2-large  \n",
       "2776  gpt2-large  \n",
       "2777  gpt2-large  \n",
       "2778  gpt2-large  \n",
       "2779  gpt2-large  \n",
       "2780  gpt2-large  \n",
       "2781  gpt2-large  \n",
       "2782  gpt2-large  \n",
       "2783  gpt2-large  \n",
       "2784  gpt2-large  \n",
       "2785  gpt2-large  \n",
       "2786  gpt2-large  \n",
       "2787  gpt2-large  \n",
       "2788  gpt2-large  \n",
       "2789  gpt2-large  \n",
       "2790  gpt2-large  \n",
       "2791  gpt2-large  \n",
       "2792  gpt2-large  \n",
       "2793  gpt2-large  \n",
       "2794  gpt2-large  \n",
       "2795  gpt2-large  \n",
       "2796  gpt2-large  \n",
       "2797  gpt2-large  \n",
       "2798  gpt2-large  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.k == 4) & (df.task == 'ethos-national_origin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8029cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "test_task = 'ethos-national_origin'\n",
    "train_data = load_data(\n",
    "    args.task, \"train\", 200, seed=seed, config_split=config_split,\n",
    "    datasets=[test_task])\n",
    "dev_data = load_data(\n",
    "    args.task, args.split, 200, seed=seed, config_split=config_split,\n",
    "    datasets=[test_task], is_null=args.is_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4993a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 09:46:57 - INFO - __main__ - Checking the first example...\n",
      "Input:\n",
      "I dare you to choke her next time. Every one of them\n",
      "false\n",
      "\n",
      "\n",
      "Fuck this faggot. He's the disrespecting idiot brother in law that loves to start fights at family functions.You can't have conversations with assholes like him.\n",
      "false\n",
      "\n",
      "\n",
      "You look like Russian and speak like Indian. Both are disgusting go kill yourself\n",
      "true\n",
      "\n",
      "\n",
      "Fucking idiots. Keep them out. They change the culture. Take over small towns. Vote in their own people to rule the town. And start enforcing their religious beliefs on everyone. It CANNOT FUCKING HAPPEN. Stop them now while you still can.\n",
      "false\n",
      "\n",
      "\n",
      "Ima fucking stab u up bruv. Fucking white prick bruv.. fucking racist.  Gammon\n",
      "Output:\n",
      "\n",
      "false\n",
      "07/06/2022 09:46:57 - INFO - __main__ - results/results_gpt2/worst/ethos-national_origin-dev-direct-k=4-s=100-no-newlines.pkl\n",
      "07/06/2022 09:47:07 - INFO - __main__ - torch.Size([292, 1024])\n",
      "07/06/2022 09:48:18 - INFO - __main__ - Accuracy=0.16091954022988506\n",
      "07/06/2022 09:48:18 - INFO - __main__ - Checking the first example...\n",
      "Input:\n",
      "fucking stupid feminist bitches\n",
      "false\n",
      "\n",
      "\n",
      "This sick, disgusting, white terrorist/fascist killed more than 50 innocent people.\n",
      "false\n",
      "\n",
      "\n",
      "Are you sure you are a girl? That wig on your legs say: I WANT TO BE A BOY\n",
      "false\n",
      "\n",
      "\n",
      "Incest baby that got double-down syndrome\n",
      "false\n",
      "\n",
      "\n",
      "Ima fucking stab u up bruv. Fucking white prick bruv.. fucking racist.  Gammon\n",
      "Output:\n",
      "\n",
      "false\n",
      "07/06/2022 09:48:18 - INFO - __main__ - results/results_gpt2/best/ethos-national_origin-dev-direct-k=4-s=100-no-newlines.pkl\n",
      "07/06/2022 09:48:18 - INFO - __main__ - torch.Size([292, 1024])\n",
      "07/06/2022 09:49:28 - INFO - __main__ - Accuracy=0.349040221523443\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "args_temp = copy.deepcopy(args)\n",
    "curr_dev_data = [dp for dp in dev_data if dp[\"task\"]==test_task]\n",
    "for k in args.ks:\n",
    "    args_temp.k = k\n",
    "    metaicl_data.k = k\n",
    "    df_k_sorted = df[(df.k == k) & (df.task == test_task)].sort_values('result')\n",
    "    curr_train_data = eval(df_k_sorted.iloc[0].train_samples)\n",
    "    assert len(curr_dev_data)>0\n",
    "    assert not args_temp.use_demonstrations or len(curr_train_data)==args_temp.k, \\\n",
    "            (args_temp.use_demonstrations, len(curr_train_data), args_temp.k)\n",
    "\n",
    "    config_file = \"config/tasks/{}.json\".format(test_task)\n",
    "    assert os.path.exists(config_file), config_file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    is_classification = config[\"task_type\"]==\"classification\"\n",
    "    if is_classification:\n",
    "        options = curr_dev_data[0][\"options\"]\n",
    "        assert np.all([d[\"options\"]==options for d in curr_dev_data])\n",
    "    args_temp.out_dir = os.path.join(args.out_dir, 'worst')\n",
    "    if not os.path.exists(args_temp.out_dir):\n",
    "        os.mkdir(args_temp.out_dir)\n",
    "    result = run(\n",
    "        logger, test_task, metaicl_data, metaicl_model,\n",
    "        curr_train_data, curr_dev_data, seed, checkpoint, is_classification, add_newlines, args_temp)\n",
    "    args_temp.out_dir = os.path.join(args.out_dir, 'best')\n",
    "    if not os.path.exists(args_temp.out_dir):\n",
    "        os.mkdir(args_temp.out_dir)\n",
    "    curr_train_data = eval(df_k_sorted.iloc[-1].train_samples)\n",
    "    result = run(\n",
    "        logger, test_task, metaicl_data, metaicl_model,\n",
    "        curr_train_data, curr_dev_data, seed, checkpoint, is_classification, add_newlines, args_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd747da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/06/2022 10:00:34 - INFO - sentence_transformers.SentenceTransformer - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "/home/mcinerney.de/.conda/envs/metaicl/lib/python3.8/site-packages/huggingface_hub/file_download.py:560: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n",
      "07/06/2022 10:00:36 - INFO - sentence_transformers.SentenceTransformer - Use pytorch device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac21f93dcda43139a2e85781b2c3136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e3e50d57a1423484ac480e8786d5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8141d0034c4522b8c916c1f0fef1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcinerney.de/.conda/envs/metaicl/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/mcinerney.de/.conda/envs/metaicl/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import difflib\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "args_temp = copy.deepcopy(args)\n",
    "for k in args.ks:\n",
    "    args_temp.k = k\n",
    "    metaicl_data.k = k\n",
    "    print(k)\n",
    "    df_k_sorted = df[(df.k == k) & (df.task == test_task)].sort_values('result')\n",
    "    out_path = get_out_name(\n",
    "        os.path.join(args.out_dir, 'worst'), test_task, args.split, metaicl_data.method, False, seed, args_temp) + '.txt'\n",
    "    with open(out_path, 'r') as f:\n",
    "        worst_answers = f.readlines()\n",
    "    out_path = get_out_name(\n",
    "        os.path.join(args.out_dir, 'best'), test_task, args.split, metaicl_data.method, False, seed, args_temp) + '.txt'\n",
    "    with open(out_path, 'r') as f:\n",
    "        best_answers = f.readlines()\n",
    "#     for line in difflib.unified_diff(worst_answers, best_answers, fromfile='worst', tofile='best', lineterm=''):\n",
    "#         print(line)\n",
    "    dev_embs = model.encode([dp['input'] for dp in dev_data if dp[\"task\"]==test_task])\n",
    "    train_embs_best = model.encode([dp['input'] for dp in eval(df_k_sorted.iloc[-1].train_samples)])\n",
    "    train_embs_worst = model.encode([dp['input'] for dp in eval(df_k_sorted.iloc[0].train_samples)])\n",
    "    if len(train_embs_best) == 0:\n",
    "        train_embs_best = train_embs_best.reshape(0, dev_embs.shape[1])\n",
    "        train_embs_worst = train_embs_worst.reshape(0, dev_embs.shape[1])\n",
    "    tsne = TSNE()\n",
    "    transformed = tsne.fit_transform(np.concatenate([dev_embs, train_embs_best, train_embs_worst]))\n",
    "    split1, split2 = len(dev_embs), len(dev_embs) + len(train_embs_best)\n",
    "    dev_embs_transformed, train_embs_best_transformed, train_embs_worst_transformed = \\\n",
    "        transformed[:split1], transformed[split1:split2], transformed[split2:]\n",
    "    embeddings = []\n",
    "    for (x, y), bestpred, worstpred, dp in zip(dev_embs_transformed, best_answers, worst_answers, [\n",
    "        dp for dp in dev_data if dp[\"task\"]==test_task]):\n",
    "        bestpred, worstpred = bestpred.strip(), worstpred.strip()\n",
    "        embeddings.append({\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            '': 'dev-same' if bestpred == worstpred else 'dev-corrected' if bestpred == dp['output'] else 'dev-corrupted',\n",
    "            'color': 'blue' if bestpred == worstpred else 'green' if bestpred == dp['output'] else 'red',\n",
    "            'size': 1 if bestpred == worstpred else 2,\n",
    "        })\n",
    "\n",
    "    for x, y in train_embs_best_transformed:\n",
    "        embeddings.append({\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            '': 'train-best',\n",
    "            'color': 'red',\n",
    "            'size': 3,\n",
    "        })\n",
    "    for x, y in train_embs_worst_transformed:\n",
    "        embeddings.append({\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            '': 'train-worst',\n",
    "            'color': 'green',\n",
    "            'size': 3,\n",
    "        })\n",
    "    embeddings = pd.DataFrame(embeddings)\n",
    "    # p = sns.scatterplot(data=embeddings, x='x', y='y', style='', hue='',\n",
    "    #                     markers={'dev-corrected': 'o', 'dev-corrupted': 'o', 'dev-same': '.', \n",
    "    #                              \"train-worst\": \"s\", \"train-best\": \"X\"})\n",
    "    sns.scatterplot(data=embeddings[embeddings[''] == 'dev-same'], x='x', y='y', color='blue', marker='.')\n",
    "    sns.scatterplot(data=embeddings[embeddings[''] == 'dev-corrected'], x='x', y='y', color='green', marker='o')\n",
    "    sns.scatterplot(data=embeddings[embeddings[''] == 'dev-corrupted'], x='x', y='y', color='red', marker='o')\n",
    "    sns.scatterplot(data=embeddings[embeddings[''] == 'train-best'], x='x', y='y', color='green', marker='+', s=200)\n",
    "    sns.scatterplot(data=embeddings[embeddings[''] == 'train-worst'], x='x', y='y', color='brown', marker='x', s=100)\n",
    "    # p.axis([-40, 25, -25, 25])\n",
    "    plt.savefig(os.path.join(args.out_dir, 'tsne_embedded_inputs_k=%i.pdf' % k))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d1fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
